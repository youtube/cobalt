/*
 * Copyright (C) 2012 Google Inc. All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 *  * Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 *  * Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
 * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
 * PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
 * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
 * OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

// https://w3c.github.io/speech-api/#speechrecognition

enum SpeechRecognitionMode {
    // On-device speech recognition if available, otherwise use Cloud speech
    // recognition as a fallback.
    "ondevice-preferred",

    // On-device speech recognition only. Throws a language-not-supported error
    // if on-device speech recognition is not available for the given language.
    "ondevice-only",

    // Cloud speech recognition only.
    "cloud-only",
};

[
    ActiveScriptWrappable,
    LegacyWindowAlias=webkitSpeechRecognition,
    LegacyWindowAlias_Measure,
    LegacyWindowAlias_RuntimeEnabled=ScriptedSpeechRecognition,
    LegacyNoInterfaceObject
] interface SpeechRecognition : EventTarget {
    [CallWith=ExecutionContext, Measure] constructor();
    // recognition parameters
    [Measure] attribute SpeechGrammarList grammars;
    attribute DOMString lang;
    attribute boolean continuous;
    attribute boolean interimResults;
    attribute unsigned long maxAlternatives;
    [RuntimeEnabled=OnDeviceWebSpeechAvailable] attribute SpeechRecognitionMode mode;
    [RuntimeEnabled=WebSpeechRecognitionContext] attribute SpeechRecognitionContext context;

    // methods to drive the speech interaction
    [RaisesException, Measure] void start();
    [RaisesException, Measure, RuntimeEnabled=MediaStreamTrackWebSpeech] void start(MediaStreamTrack track);
    [ImplementedAs=stopFunction] void stop();
    void abort();
    [
        RaisesException,
        RuntimeEnabled=WebSpeechRecognitionContext
    ] void updateContext(SpeechRecognitionContext context);
    [
        CallWith=ScriptState,
        RaisesException,
        RuntimeEnabled=OnDeviceWebSpeechAvailable
    ] static Promise<boolean> availableOnDevice(DOMString lang);
    [
        CallWith=ScriptState,
        RaisesException,
        RuntimeEnabled=InstallOnDeviceSpeechRecognition
    ] static Promise<boolean> installOnDevice(DOMString lang);

    // event methods
    attribute EventHandler onaudiostart;
    attribute EventHandler onsoundstart;
    attribute EventHandler onspeechstart;
    attribute EventHandler onspeechend;
    attribute EventHandler onsoundend;
    attribute EventHandler onaudioend;
    attribute EventHandler onresult;
    attribute EventHandler onnomatch;
    attribute EventHandler onerror;
    attribute EventHandler onstart;
    attribute EventHandler onend;
};
