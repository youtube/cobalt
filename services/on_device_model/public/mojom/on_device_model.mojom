// Copyright 2023 The Chromium Authors
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

module on_device_model.mojom;

import "mojo/public/mojom/base/file.mojom";
import "mojo/public/mojom/base/file_path.mojom";
import "skia/public/mojom/bitmap.mojom";

// Opened file resources needed to define an adaptation.
[Stable]
struct AdaptationAssets {
  // Model weights could be passed as an opened file or a file path.
  // The backend type will decide which one should be used, or
  // which one is preferred if both are passed. If both are unset,
  // usually the operation should fail.
  // APU backend: weights_path should be used.
  // GPU backend: weights should be used.
  // TODO(b/313919363): This should also be a ReadOnlyFile.
  mojo_base.mojom.File? weights;
  mojo_base.mojom.FilePath? weights_path;
};

// Conveys the result of a language detection attempt on output text.
[Stable]
struct LanguageDetectionResult {
  // Language code of the detected language. If detection was indeterminate,
  // this is "und" per ISO 639-2.
  string code;

  // Reliability of this result, in the range [0, 1].
  float reliability;
};

// Aggregated text safety evaluation results.
[Stable]
struct SafetyInfo {
  // Independent safety class probabilities in the range [0, 1].
  array<float> class_scores;

  // Language detection information. Present if and only if the safety config is
  // restricted by language.
  LanguageDetectionResult? language;
};

// Partial response received via StreamingResponder.OnResponse().
[Stable]
struct ResponseChunk {
  // Text for this chunk of the response.
  string text;

  // Optional safety information computed against the full response so far, up
  // to and including `text`.
  SafetyInfo? safety_info;
};

// Information pertaining to a complete response that was streamed by a
// StreamingResponder.
[Stable]
struct ResponseSummary {
  // Optional safety information computed against the full response.
  SafetyInfo? safety_info;

  // Deprecated: Execute() is now deprecated and input should be passed through
  // Append().
  uint32 input_token_count;

  // The total number of output tokens for this response.
  uint32 output_token_count;
};

// Streams a response from a call to execute a model. Close this pipe to cancel
// the call to |Execute()|.
[Stable]
interface StreamingResponder {
  // This is called each time a new chunk of text is available.
  OnResponse@0(ResponseChunk chunk);

  // This is called once when all text for the query has been returned. No other
  // methods on this interface will be called after OnComplete(). `summary`
  // conveys metadata about the response that was streamed.
  OnComplete@1(ResponseSummary summary);
};

// Notifies the caller when the model is done processing context. Close this
// pipe to cancel the call to |AddContext()|.
[Stable]
interface ContextClient {
  // Called when the context has finished processing with the number of tokens
  // processed.
  OnComplete@0(uint32 tokens_processed);
};

// Params to describe the adaptation to load.
[Stable]
struct LoadAdaptationParams {
  // Assets for an adaptation.
  AdaptationAssets assets;

  // The maximum number of input+output tokens the adaptation model can handle.
  // This is needed when initializing the model. Currently this is only
  // supported by the APU backend.
  // When set to 0, the original `max_tokens` set by the base model will be
  // used.
  uint32 max_tokens = 0;

  // Whether this model will handle InputPieces containing images.
  [MinVersion=1]
  bool enable_image_input = false;
  // Whether this model will handle InputPieces containing audio.
  [MinVersion=2]
  bool enable_audio_input = false;
};

// The set of tokens that can be added as part of an input.
[Stable, Extensible]
enum Token {
  // Prefix for system text.
  kSystem,
  // Prefix for model text.
  kModel,
  // Prefix for user text.
  kUser,
  // End a system/model/user section.
  [Default] kEnd,
};

// Holds the possible input types to the model. Note that if any of these input
// types include cross-origin data, such as a screenshot, any of the origins may
// be able to control the model output.
[Stable, Extensible]
union InputPiece {
  // A token which may have different internal representations depending on the
  // loaded model.
  Token token;
  // Text to be provided as input.
  string text;
  // Bitmap provided as input. This is not ImageSkia because there is no desire
  // to support multiple scale factors. The bitmap is supplied by the
  // browser process.
  skia.mojom.BitmapMappedFromTrustedProcess bitmap;

  // Used to handle version skew.
  [Default]
  bool unknown_type;

  // Audio provided as input.
  [MinVersion=1]
  AudioData audio;
};

[Stable]
struct Input {
  // A list of tokens and text that the model will use to construct the final
  // input.
  array<InputPiece> pieces;
};

// Options to control how the model handles input.
[Stable]
struct InputOptions {
  // The input for the model.
  Input input;

  // The maximum number of tokens that should be processed. If zero, will
  // process all tokens from this input.
  uint32 max_tokens = 0;

  // After text is tokenized, the offset into that vector to start processing.
  // If zero, will start at the first token.
  uint32 token_offset = 0;

  // If this is true, indicates this is a one-off call that wants to ignore the
  // context for this input. Note that this is less efficient than running on
  // top of the current context, so only use when necessary.
  bool ignore_context;

  // The maximum number of tokens that should be output from a call to
  // Execute(). If zero, will output tokens until an end token or the maximum
  // sequence length.
  uint32 max_output_tokens = 0;

  // These params control the output sampling. Higher `top_k` means more tokens
  // are considered, higher `temperature` means less likely tokens are more
  // probable.
  // `top_k` should be a value from 1 to the max top K value the model was
  // initialized with.
  uint32? top_k;
  // `temperature` should be a value greater than 0.0. Values above 1.0 may give
  // poor results.
  float? temperature;
};

[Stable]
struct AppendOptions {
  // The input for the model.
  Input input;

  // The maximum number of tokens that should be processed. If zero, will
  // process all tokens from this input.
  uint32 max_tokens = 0;

  // After text is tokenized, the offset into that vector to start processing.
  // If zero, will start at the first token.
  uint32 token_offset = 0;
};

[Stable]
struct GenerateOptions {
  // The maximum number of tokens that should be output from a call to
  // Execute(). If zero, will output tokens until an end token or the maximum
  // sequence length.
  uint32 max_output_tokens = 0;

  // These params control the output sampling. Higher `top_k` means more tokens
  // are considered, higher `temperature` means less likely tokens are more
  // probable.
  // `top_k` should be a value from 1 to the max top K value the model was
  // initialized with.
  uint32? top_k;
  // `temperature` should be a value greater than 0.0. Values above 1.0 may give
  // poor results.
  float? temperature;
};

// A session for a model that allows adding context and then executing an input
// with that context.
[Stable]
interface Session {
  // Deprecated: use Append() instead.
  AddContext@0(InputOptions input, pending_remote<ContextClient>? client);
  // Appends input to this session. Any input added here will build off of
  // previous calls to |Append()|. To cancel, close the |client| pipe.
  [MinVersion=1]
  Append@6(AppendOptions options, pending_remote<ContextClient>? client);

  // Deprecated: use Generate() instead.
  Execute@1(InputOptions input, pending_remote<StreamingResponder> response);
  // Generates output from the model on top of any input added from Append().
  // The response will be streamed to |response|. To cancel the request, close
  // the |response| pipe.
  [MinVersion=1]
  Generate@7(
      GenerateOptions options, pending_remote<StreamingResponder> response);

  // Gets the size of the given text in tokens. Will return 0 if the text is
  // empty or error occurred.
  GetSizeInTokens@5(Input input) => (uint32 size);

  // Gets the probability score of the first token in `text` on top of the
  // current context.
  Score@3(string text) => (float probability);

  // Clones the current session. The cloned session will have the same context
  // as the current session.
  Clone@4(pending_receiver<Session> session);
};

// A loaded model which can be queried. This interface must be controlled by the
// browser and consumers must take care to sanitize inputs.
[Stable]
interface OnDeviceModel {
  // Starts a session with this model. If a session starts before the previous
  // one has completed and the multiple sessions support is not enabled for
  // this model, the previous session will be canceled, the mojo connection
  // for the previous session will also be closed, and the ongoing connections
  // of StreamingResponder & ContextClient will also be closed.
  // When the multiple sessions support is enabled, nothing will be
  // disconnected, and the further requests will be queued.
  StartSession@0(pending_receiver<Session> session);

  // Infers multiclass safety scores for the given `text` using this model's
  // underlying safety classifier, if any. Returns null if classification fails
  // or there is no classifier available.
  ClassifyTextSafety@1(string text) => (SafetyInfo? safety_info);

  // Detects the language of the text using the language classifier. Returns
  // null if there is no classifier available.
  DetectLanguage@2(string text) => (LanguageDetectionResult? result);

  // Loads an adaptation with the specified params. This will always load the
  // adaptation on top of the base model.
  LoadAdaptation@3(
      LoadAdaptationParams params, pending_receiver<OnDeviceModel> model)
      => (LoadModelResult result);
};

interface TextSafetyModel {
  // Infers multiclass safety scores for the given `text` using this model's
  // underlying safety classifier, if any. Returns null if classification fails
  // or there is no classifier available.
  ClassifyTextSafety@1(string text) => (SafetyInfo? safety_info);

  // Detects the language of the text using the language classifier. Returns
  // null if there is no classifier available.
  DetectLanguage@2(string text) => (LanguageDetectionResult? result);
};

// Classifies the device based on how fast it is estimated to be able to run a
// model.
[Stable, Extensible]
enum PerformanceClass {
  // There was an error running the benchmark. The device is likely not able to
  // run any models.
  [Default] kError,
  // The GPU was blocked so the benchmark could not run.
  kGpuBlocked,
  // The library failed to load so the benchmark could not run.
  kFailedToLoadLibrary,

  // The values below classify devices into a range of performance buckets.
  kVeryLow,
  kLow,
  kMedium,
  kHigh,
  kVeryHigh,
};

[Stable, Extensible]
enum LoadModelResult {
  kSuccess,
  kGpuBlocked,
  [Default] kFailedToLoadLibrary,
};

[Stable]
struct AudioData {
  // Number of channels.
  int32 channel_count;

  // Sample rate of the buffer.
  int32 sample_rate;

  // Number of frames in the buffer.
  int32 frame_count;

  // Channel data.
  array<float> data;
};
