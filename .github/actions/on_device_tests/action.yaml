name: On Device Test
description: Runs on-device tests.
inputs:
  test_targets_json:
    description: "The test targets in a JSON array."
    required: true
  gcs_results_path:
    description: "GCS path for the test results."
    required: true
  test_results_key:
    description: "Artifact key used to store test results."
    required: true
  test_dimensions:
    description: "Test dimensions JSON string."
    required: true
  test_device_family:
    description: "Test device family."
    required: true
  test_attempts:
    description: "Number of attempts for the tests."
    default: ""
  test_targets_filter:
    description: "jq filter to apply to the test targets."
    default: "."

runs:
  using: "composite"
  steps:
    - name: Install Requirements
      run: |
        pip3 install --require-hashes --no-deps -r ${GITHUB_WORKSPACE}/cobalt/tools/requirements.txt
      shell: bash
    - name: Generate gRPC files
      run: |
        python -m grpc_tools.protoc -I${GITHUB_WORKSPACE}/cobalt/tools/ \
            --python_out=${GITHUB_WORKSPACE}/cobalt/tools/ \
            --grpc_python_out=${GITHUB_WORKSPACE}/cobalt/tools/ \
            ${GITHUB_WORKSPACE}/cobalt/tools/on_device_tests_gateway.proto
      shell: bash
    - name: Set Up Cloud SDK
      uses: isarkis/setup-gcloud@40dce7857b354839efac498d3632050f568090b6 # v1.1.1
    - name: Set GCS Project Name
      run: |
        echo "PROJECT_NAME=$(gcloud config get-value project)" >> $GITHUB_ENV
      shell: bash
    - name: Run Tests on ${{ matrix.platform }} Platform
      env:
        GCS_ARTIFACTS_PATH: /bigstore/${{ env.PROJECT_NAME }}-test-artifacts/${{ github.workflow }}/${{ github.run_number }}/${{ matrix.platform }}
        GITHUB_SHA: ${{ github.sha }}
        GITHUB_RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
        GITHUB_WORKFLOW: ${{ github.workflow }}
        TEST_TYPE: unit_test
        TEST_TARGETS_FILTER: ${{ inputs.test_targets_filter }}
      run: |
        set -x

        # Filter test targets.
        TEST_TARGETS_JSON=$(echo '${{ inputs.test_targets_json }}' | jq -cr "[.[] | ${TEST_TARGETS_FILTER}]")
        if [[ $(echo "${TEST_TARGETS_JSON}" | jq 'length') -eq 0 ]]; then
          echo "No tests to run after filtering."
          exit 0
        fi

        # TODO(oxv): Fix dimensions. Pass as json? key-value pair?
        python3 -u cobalt/tools/on_device_tests_gateway_client.py \
          --token ${{ github.token }} \
          trigger \
          --test_type ${TEST_TYPE} \
          --device_family '${{ inputs.test_device_family }}' \
          --targets "${TEST_TARGETS_JSON}" \
          --filter_json_dir "${GITHUB_WORKSPACE}/cobalt/testing/filters/${{ matrix.platform }}" \
          --label chrobalt_on_device_test \
          --label github_${{ github.event.pull_request.number || 'postsubmit' }} \
          --label builder-${{ matrix.platform }} \
          --label builder_url-${GITHUB_RUN_URL} \
          --label ${TEST_TYPE} \
          --label github \
          --label ${{ github.event_name }} \
          --label ${GITHUB_WORKFLOW} \
          --label actor-${{ github.actor }} \
          --label actor_id-${{ github.actor_id }} \
          --label triggering_actor-${{ github.triggering_actor }} \
          --label sha-${GITHUB_SHA} \
          --label repository-${{ github.repository }} \
          --label author-${{ github.event.pull_request.head.user.login || github.event.commits[0].author.username }} \
          --label author_id-${{ github.event.pull_request.head.user.id || github.event.commits[0].author.email }} \
          --label branch:${{ github.ref_name }} \
          --dimensions '${{ inputs.test_dimensions }}' \
          ${{ inputs.test_attempts && format('--test_attempts {0}', inputs.test_attempts) }} \
          --gcs_archive_path "${GCS_ARTIFACTS_PATH}" \
          --gcs_result_path "${{ inputs.gcs_results_path }}" || {
            echo "Finished running tests..."
            echo "The test session failed. See logs for details."
            # Fail the job so it's easy to retrigger.
            exit 1
          }
        echo "Finished running tests..."
      shell: bash
    - name: Download ${{ matrix.platform }} Test Results from GCS
      if: always()
      env:
        TEST_TARGETS_FILTER: ${{ inputs.test_targets_filter }}
      run: |
        set -uxe
        shopt -s globstar nullglob

        # Filter test targets for result verification as well.
        TEST_TARGETS_JSON=$(echo '${{ inputs.test_targets_json }}' | jq -cr "[.[] | ${TEST_TARGETS_FILTER}]")
        if [[ $(echo "${TEST_TARGETS_JSON}" | jq 'length') -eq 0 ]]; then
          echo "No tests to download results for after filtering."
          exit 0
        fi

        test_output="${GITHUB_WORKSPACE}/results"
        echo "test_output=${test_output}" >> $GITHUB_ENV

        # Test results (xml and logs) must be in a subfolder in results_dir.
        # to be picked up by the test result processor.
        mkdir -p "${test_output}/${{ matrix.platform }}"
        gsutil -q cp -r "${{ inputs.gcs_results_path }}/" "${test_output}/${{ matrix.platform }}"

        # Check for missing result xml files.
        readarray -t test_targets < <(echo "$TEST_TARGETS_JSON" | jq -r '.[]')
        for test_target_with_path in "${test_targets[@]}"; do
          # Trim path prefix (before :).
          test_target=${test_target_with_path#*:}
          xml_files=("${test_output}"/${{ matrix.platform }}/**/"${test_target}"_testoutput.xml)
          if [[ "${#xml_files[@]}" -eq 0 ]]; then
            # No matching XML results found. Check if the test target is filtered.
            test_filter_file="${GITHUB_WORKSPACE}/cobalt/testing/filters/${{ matrix.platform }}/${test_target}_filter.json"
            if [ ! -f "${test_filter_file}" ] || [ "$(jq -cr '.failing_tests[0]' "${test_filter_file}")" != '*' ]; then
              echo "Test result xml is missing for ${test_target}."

              # Try to find the crashed test in the log and create a fake junit xml for it.
              log_path=("${test_output}"/${{ matrix.platform }}/**/"${test_target}"_log.txt)
              xml_path=("${test_output}"/${{ matrix.platform }}/1/"${test_target}"_testoutput.xml)
              python3 ${GITHUB_WORKSPACE}/.github/scripts/generate_crash_report.py "${log_path}" "${xml_path}"
              exit 1
            fi
          elif grep -e '<failure' -e '<error' ${xml_files}; then
            # Double-check the result XML for failures. ODT service has been known to report incorrect status.
            echo "::error::Found failures in the test xml."
            exit 1
          fi
        done
      shell: bash
    - name: Archive Test Results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: ${{ inputs.test_results_key }}
        path: ${{ env.test_output }}/*
    - name: Get Deflake Max Attempts
      id: deflake-attempts
      run: |
        MAX_ATTEMPTS=$(jq -r '.deflake_runs | tonumber? // 1' ${GITHUB_WORKSPACE}/.github/config/infra/deflake.json)
        echo "max_attempts=${MAX_ATTEMPTS}" >> $GITHUB_OUTPUT
      shell: bash
    - name: Run Nightly Deflake
      # Deflake workflow retries MAX_ATTEMPTS times. Pass the last to keep dashboard green.
      if: github.event_name == 'schedule' && github.run_attempt != steps.deflake-attempts.outputs.max_attempts
      run: echo "::warning::Triggering deflaking run by failing." && exit 1
      shell: bash
