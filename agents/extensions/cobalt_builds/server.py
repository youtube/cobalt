#!/usr/bin/env vpython3
# Copyright 2025 The Cobalt Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""A MCP server for building and running Cobalt binaries."""

# [VPYTHON:BEGIN]
# python_version: "3.11"
# wheel: <
#   name: "infra/python/wheels/mcp-py3"
#   version: "version:1.9.4"
# >
# wheel: <
#   name: "infra/python/wheels/pydantic-py3"
#   version: "version:2.11.7"
# >
# wheel: <
#   name: "infra/python/wheels/starlette-py3"
#   version: "version:0.47.1"
# >
# wheel: <
#   name: "infra/python/wheels/anyio-py3"
#   version: "version:4.9.0"
# >
# wheel: <
#   name: "infra/python/wheels/sniffio-py3"
#   version: "version:1.3.0"
# >
# wheel: <
#   name: "infra/python/wheels/idna-py3"
#   version: "version:3.4"
# >
# wheel: <
#   name: "infra/python/wheels/typing-extensions-py3"
#   version: "version:4.13.2"
# >
# wheel: <
#   name: "infra/python/wheels/httpx_sse-py3"
#   version: "version:0.4.1"
# >
# wheel: <
#   name: "infra/python/wheels/httpx-py3"
#   version: "version:0.28.1"
# >
# wheel: <
#   name: "infra/python/wheels/certifi-py3"
#   version: "version:2025.4.26"
# >
# wheel: <
#   name: "infra/python/wheels/httpcore-py3"
#   version: "version:1.0.9"
# >
# wheel: <
#   name: "infra/python/wheels/h11-py3"
#   version: "version:0.16.0"
# >
# wheel: <
#   name: "infra/python/wheels/pydantic-settings-py3"
#   version: "version:2.10.1"
# >
# wheel: <
#   name: "infra/python/wheels/python-multipart-py3"
#   version: "version:0.0.20"
# >
# wheel: <
#   name: "infra/python/wheels/sse-starlette-py3"
#   version: "version:2.4.1"
# >
# wheel: <
#   name: "infra/python/wheels/uvicorn-py3"
#   version: "version:0.35.0"
# >
# wheel: <
#   name: "infra/python/wheels/annotated-types-py3"
#   version: "version:0.7.0"
# >
# wheel: <
#   name: "infra/python/wheels/pydantic_core/${vpython_platform}"
#   version: "version:2.33.2"
# >
# wheel: <
#   name: "infra/python/wheels/typing-inspection-py3"
#   version: "version:0.4.1"
# >
# wheel: <
#   name: "infra/python/wheels/python-dotenv-py3"
#   version: "version:1.1.1"
# >
# wheel: <
#   name: "infra/python/wheels/click-py3"
#   version: "version:8.0.3"
# >
# [VPYTHON:END]

import argparse
import asyncio
import json
import os
import re
import signal
import subprocess
import time
import uuid
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
from typing import Dict, List
import logging
from mcp.server.fastmcp import FastMCP
from pydantic import BaseModel

from analysis import analyze_log
import config

# Suppress informational logs from the MCP server
logging.getLogger('mcp').setLevel(logging.WARNING)

from build_helpers import (
    PLATFORM_ALIASES,
    TaskStatus,
    get_out_dir,
    get_platform
)

RUNNABLE_PLATFORMS = [
    'evergreen-x64', 'linux-x64x11', 'linux-x64x11-modular',
    'linux-x64x11-no-starboard'
]

# --- MCP Server Setup ---
mcp = FastMCP(
    'cobalt_builds',
    'A server for building and running Cobalt binaries.',
)

executor = ThreadPoolExecutor(max_workers=4)

# All status is now derived from the filesystem, no in-memory storage needed.


def _generate_task_id(task_type: str, name: str) -> str:
  """Generates a human-readable task ID."""
  timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
  return f'{task_type}_{name}_{timestamp}'


class TaskRunner:
  """A class to encapsulate the logic for running build and test tasks."""

  def __init__(self, task_id: str, cmd: List[str], log_path: str):
    self.task_id = task_id
    self.cmd = cmd
    self.log_path = log_path

  def run_sync(self):
    """Runs the task synchronously."""
    try:
      with open(self.log_path, 'w') as log_file:
        log_file.write(' '.join(self.cmd) + '\n')
        log_file.flush()

        process = subprocess.Popen(
            self.cmd, stdout=log_file, stderr=subprocess.STDOUT)
        process.wait()

        log_file.write(f'\nRETURN_CODE: {process.returncode}\n')

    except Exception as e:
      with open(self.log_path, 'a') as log_file:
        log_file.write(f'\nTHREAD_EXCEPTION: {e}\n')
        log_file.write(f'\nRETURN_CODE: -1\n')

  async def run_async(self):
    """Runs the task asynchronously."""
    try:
      with open(self.log_path, 'w') as log_file:
        log_file.write(' '.join(self.cmd) + '\n')
        log_file.flush()
        process = await asyncio.create_subprocess_exec(
            *self.cmd, stdout=log_file, stderr=subprocess.STDOUT)
        await process.wait()

      with open(self.log_path, 'a') as f:
        f.write(f'\nRETURN_CODE: {process.returncode}\n')

    except FileNotFoundError:
      with open(self.log_path, 'a') as f:
        f.write(f'\nERROR: Binary not found: {self.cmd[0]}\n')
        f.write(f'\nRETURN_CODE: -1\n')


# --- Tool Definitions ---
@mcp.tool()
def get_supported_platforms() -> List[str]:
  """Returns a list of supported platforms, their aliases, and whether they are runnable."""
  gn_py_path = './cobalt/build/gn.py'
  platforms = []
  try:
    with open(gn_py_path, 'r') as f:
      content = f.read()
      chromium_platforms = re.search(r'_CHROMIUM_PLATFORMS = \[(.*?)\]',
                                     content, re.DOTALL)
      if chromium_platforms:
        platforms.extend(
            [p.strip().strip("'" ) for p in chromium_platforms.group(1).split(',')
             if p.strip()])
      cobalt_starboard_platforms = re.search(
          r'_COBALT_STARBOARD_PLATFORMS = \[(.*?)\]', content, re.DOTALL)
      if cobalt_starboard_platforms:
        platforms.extend([
            p.strip().strip("'" )
            for p in cobalt_starboard_platforms.group(1).split(',')
            if p.strip()
        ])
      cobalt_android_platforms = re.search(
          r'_COBALT_ANDROID_PLATFORMS = \[(.*?)\]', content, re.DOTALL)
      if cobalt_android_platforms:
        platforms.extend([
            p.strip().strip("'" )
            for p in cobalt_android_platforms.group(1).split(',') if p.strip()
        ])
  except IOError as e:
    return [f"Error reading platforms from {gn_py_path}: {e}"]

  reversed_aliases = {v: k for k, v in PLATFORM_ALIASES.items()}
  formatted_platforms = []
  for p in sorted(list(set(platforms))):
    info = []
    alias = reversed_aliases.get(p)
    if alias:
      info.append(f'alias: {alias}')
    if p in RUNNABLE_PLATFORMS:
      info.append('runnable')

    if info:
      formatted_platforms.append(f"{p} ({', '.join(info)})")
    else:
      formatted_platforms.append(p)
  formatted_platforms.append('--- END OF PLATFORMS ---')
  return formatted_platforms


@mcp.tool()
def configure_build(platform: str, variant: str) -> str:
  """Configures a build and returns the output directory."""
  out_dir = get_out_dir(platform, variant)
  cmd = [
      './cobalt/build/gn.py',
      f'-p={get_platform(platform)}',
      f'-c={variant}',
      out_dir
  ]
  subprocess.run(cmd, check=True)
  return out_dir


def _get_final_task_result(task_id: str, cmd: List[str]) -> str:
    """Formats the final result of a synchronous build or run task."""
    task_status = status(task_id)
    status_dict = task_status.model_dump()

    task_type = 'build' if task_id.startswith('build_') else 'run'
    status_dict[f'{task_type}_id'] = task_id
    status_dict['command'] = ' '.join(cmd)

    if task_status.status == 'success':
        message = f"âœ… {task_type.capitalize()} '{task_id}' completed successfully."
        log_snippet = ""
        try:
            with open(task_status.output_log, 'r') as f:
                lines = f.readlines()
            # Get last 5 non-empty lines, stripping them
            log_snippet = '\n'.join([line.strip() for line in lines if line.strip()][-5:])
        except Exception as e:
            log_snippet = f"Could not read log snippet: {e}"

        status_dict['message'] = message
        status_dict['log_snippet'] = log_snippet
        return json.dumps(status_dict)
    else:  # Handles 'failure' and any other non-success status
        return analyze_log(task_id)


@mcp.tool()
async def build(platform: str,
              variant: str,
              target: str,
              extra_args: List[str] | None = None,
              dry_run: bool = False,
              background: bool = False) -> str:
  """Starts a build. By default, it waits for completion.

  To run in the background, set the 'background' parameter to True.
  When running in the background, use the 'status' tool with the returned
  'build_id' to check for completion.
  If the build fails, the log will be automatically analyzed.
  """
  out_dir = get_out_dir(platform, variant)
  cmd = ['autoninja', '-C', out_dir, target]
  if extra_args:
    cmd.extend(extra_args)
  if dry_run:
    return json.dumps({'command': ' '.join(cmd)})

  build_id = _generate_task_id('build', target)
  log_path = f'/tmp/{build_id}.log'

  build_info_path = f'/tmp/{build_id}.json'
  build_info = {
      'platform': platform,
      'variant': variant,
      'target': target,
      'extra_args': extra_args,
  }
  with open(build_info_path, 'w') as f:
    json.dump(build_info, f)

  task_runner = TaskRunner(build_id, cmd, log_path)
  loop = asyncio.get_running_loop()

  if background:
    loop.run_in_executor(executor, task_runner.run_sync)
    return json.dumps({
        'build_id': build_id,
        'command': ' '.join(cmd),
        'output_log': log_path,
        'status': 'in_progress'
    })
  else:
    # Run synchronously
    await loop.run_in_executor(executor, task_runner.run_sync)
    return _get_final_task_result(build_id, cmd)


@mcp.tool()
async def run(platform: str | None = None,
            variant: str | None = None,
            binary_name: str | None = None,
            build_id_or_log_file: str | None = None,
            args: List[str] | None = None,
            dry_run: bool = False,
            debug: bool = False,
            background: bool = False) -> str:
  """Runs a binary. By default, it waits for completion.

  To run in the background, set the 'background' parameter to True.
  When running in the background, use the 'status' tool with the returned
  'run_id' to check for completion.
  If the run fails, the log will be automatically analyzed.

  Can be called in two ways:
  1. By providing `platform`, `variant`, and `binary_name`.
  2. By providing a `build_id_or_log_file` from a previous build.

  Additional arguments can be passed to the binary via the `args` list.
  """
  if build_id_or_log_file:
    if platform or variant or binary_name:
      return json.dumps({
          'error':
              'Cannot specify both build_id_or_log_file and platform/variant/binary_name.'
      })
    task_id = build_id_or_log_file
    if '/' in task_id:
      task_id = os.path.basename(task_id).replace('.log', '')

    build_info_path = f'/tmp/{task_id}.json'
    if not os.path.isfile(build_info_path):
      return json.dumps(
          {'error': f'Build info file not found: {build_info_path}'})
    try:
      with open(build_info_path, 'r') as f:
        build_info = json.load(f)
        platform = build_info.get('platform')
        variant = build_info.get('variant')
        binary_name = build_info.get('target')
    except (IOError, json.JSONDecodeError) as e:
      return json.dumps(
          {'error': f'Error reading build info from {build_info_path}: {e}'})

  if not all([platform, variant, binary_name]):
    return json.dumps({
        'error':
            'Must provide either build_id_or_log_file or platform, variant, and binary_name.'
    })

  if 'android' in platform:
    return json.dumps({'error': 'Running on Android is not yet supported.'})

  executable_name = binary_name
  if 'modular' in platform or 'evergreen' in platform:
    if not binary_name.endswith('_loader'):
      executable_name = f'{binary_name}_loader'

  out_dir = get_out_dir(platform, variant)
  cmd = [f'{out_dir}/{executable_name}']
  if args:
    cmd.extend(args)

  if debug:
    cmd = ['gdb', '-ex="set confirm off"', '-ex=r', '-ex=bt', '-ex=q', '--args'] + cmd

  if dry_run:
    return json.dumps({'command': ' '.join(cmd)})

  run_id = _generate_task_id('run', binary_name)
  log_path = f'/tmp/{run_id}.log'

  task_runner = TaskRunner(run_id, cmd, log_path)

  if background:
    asyncio.create_task(task_runner.run_async())
    return json.dumps({
        'run_id': run_id,
        'command': ' '.join(cmd),
        'output_log': log_path,
        'status': 'in_progress'
    })
  else:
    await task_runner.run_async()
    return _get_final_task_result(run_id, cmd)


@mcp.tool()
def stop(task_id: str) -> bool:
  """Stops a running task."""
  log_path = f'/tmp/{task_id}.log'
  if not os.path.exists(log_path):
    return False
  try:
    result = subprocess.run(
        ['fuser', log_path], capture_output=True, text=True, check=True)
    pid_to_kill = int(result.stdout.strip().split()[0])
    os.kill(pid_to_kill, signal.SIGTERM)
    # Best effort to mark the log as cancelled.
    with open(log_path, 'a') as f:
      f.write('\nRETURN_CODE: CANCELLED\n')
    return True
  except (FileNotFoundError, subprocess.CalledProcessError,
          ProcessLookupError, ValueError):
    return False




@mcp.tool()
def status(task_id: str) -> TaskStatus:
  """Checks the status of a task."""
  log_path = f'/tmp/{task_id}.log'

  if not os.path.exists(log_path):
    return TaskStatus(status='not_found', output_log='')

  # Use fuser as the source of truth for "in_progress"
  try:
    result = subprocess.run(
        ['fuser', log_path], capture_output=True, text=True)
    if result.stdout.strip():
      pid = int(result.stdout.strip().split()[0])
      return TaskStatus(status='in_progress', output_log=log_path, pid=pid)
  except (FileNotFoundError, ValueError):
    pass # Fall through to log check

  # If fuser finds no process, the task is finished.
  try:
    with open(log_path, 'r') as f:
      if 'RETURN_CODE: 0' in f.read():
        return TaskStatus(status='success', output_log=log_path)
  except IOError:
    pass # Fall through to failure

  # If the process is gone and there's no success marker, it's a failure.
  return TaskStatus(status='failure', output_log=log_path)


@mcp.tool()
def analyze(task_id_or_log_file: str, log_type: str | None = None) -> str:
  """Analyzes a log for errors and warnings.

  Accepts either a task ID from a build or run, or a direct path to a log file.
  The `log_type` can be 'build' or 'test'. If not provided, it's inferred
  from the log file name (e.g., 'build_...' or 'run_...').
  """
  return analyze_log(task_id_or_log_file, log_type)


# --- Server Main ---
def main():
  """Main entry point for the server."""
  parser = argparse.ArgumentParser()
  parser.add_argument(
      '--serve', action='store_true', help='Run in stdio server mode.')
  args = parser.parse_args()

  if args.serve:
    mcp.run(transport='stdio')
  else:
    print('This script is a server. Run with --serve to start.')


if __name__ == '__main__':
  main()
