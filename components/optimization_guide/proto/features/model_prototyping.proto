// Copyright 2024 The Chromium Authors
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

syntax = "proto3";

package optimization_guide.proto;

import "components/optimization_guide/proto/features/common_quality_data.proto";

import "components/optimization_guide/proto/model_quality_metadata.proto";

option optimize_for = LITE_RUNTIME;
option java_package = "org.chromium.components.optimization_guide.features.proto";

option java_outer_classname = "ModelPrototypingProto";

// DO NOT EDIT THIS FILE DIRECTLY!
//
// This file is generated in g3 and then synced to Chrome. Instead, please
// refer to http://go/chrome-intelligence-feature-protos (Google-internal link),
// and then changes will be synced with Chrome automatically.

message ModelPrototypingLoggingData {
  ModelPrototypingRequest request = 1;

  ModelPrototypingResponse response = 2;

  ModelPrototypingMetadata metadata = 3;

  ModelExecutionInfo model_execution_info = 6;
}

message ModelPrototypingRequest {
  ModelingInputs modeling_inputs = 1;

  // The series of prompts to send to the model(s). The calls are run in series
  // and the responses can be used in future calls allowing piping the output of
  // one query into the input of the next.
  repeated PrototypingPrompt prototyping_prompts = 2;

  // The responses from previous calls to the model. Can be used in future
  // prompts. Syntax for accessing them is golang text/templates
  // e.g., something like {{index .GetModelResponses 0}}.
  repeated string model_responses = 3;

  // Defines a single prompt to be sent to the model.
  message PrototypingPrompt {
    // Prompt variables that can be used in the rest of the prompt. These are in
    // addition to any prompt variables defined in the prompt template in the
    // config for the model sequence. Prompt variables are helper functions that
    // can be used in the prompt. For example, a prompt variable could be
    // something like:
    // {{ $funVar := "1" }}
    // This would define a function that can be used in the prompt as
    // {{$funVar}}. The value of the function is "1".
    string prompt_variables = 1;

    // The prompt is composed by inserting the following roles into the prompt
    // template in the order they are defined.
    // Role system is generally the instructions for the model to follow.
    string system_instructions_template = 2;

    // Role context is the information around the user interaction such as page
    // state.
    string context_area_template = 3;

    // Role user is the information from the user such as a user input they
    // typed.
    string user_input_template = 4;

    // Information about the model to use.
    ModelInformation model_information = 5;

    // The image to use in the prompt.
    string image_template = 6;

    // The pre-existing conversation between the user and the model.
    Conversation conversation = 7;

    message ModelInformation {
      ModelEnum model_enum = 1;

      bool skip_model = 2;

      enum ModelEnum {
        MODEL_ENUM_UNSPECIFIED = 0;

        MODEL_ENUM_EVERGREEN_GEMINI_V2 = 1;

        MODEL_ENUM_SUP_GEMINI_V2 = 2;

        MODEL_ENUM_EVERGREEN_GEMINI_V2_MULTI_MODAL = 3;

        MODEL_ENUM_EVERGREEN_GEMINI_V2_MULTI_MODAL_MPP = 4;
      }
    }
  }

  // Data specific to the feature.
  message ModelingInputs {
    BrowserCollectedInformation browser_collected_information = 1;

    string user_input = 2;
  }
}

// A representation of an ongoing conversation.
message Conversation {
  // The turns of various messages in the conversation.
  repeated ConversationTurn conversation_turns = 1;
}

// A single turn in a conversation.
message ConversationTurn {
  // The text of the conversation turn.
  string conversation_text = 1;

  // Which participant in the conversation this turn is from.
  string role = 2;

  // The mime type of the conversation turn.
  string mime_type = 3;
}

message ModelPrototypingResponse {
  // The series of prompts sent to the model corresponding to the
  // |prototyping_prompts| in the request.
  repeated string model_prompts = 1;

  // The responses from the model corresponding to |model_prompts|.
  repeated string model_responses = 2;

  // Ordered conversation between the user and the model.
  repeated Conversation conversations = 3;
}

message ModelPrototypingMetadata {
  // An optional tag to use for querying the record from MQLS logs.
  string logging_tag = 1;

  // An optional description to provide more context about the data uploaded by
  // the user.
  string logging_description = 2;
}
