<!DOCTYPE html>
<html>
  <head>
    <title>
      Test ChannelMergerNode with a cyclic graph
    </title>
    <script src="../../resources/testharness.js"></script>
    <script src="../../resources/testharnessreport.js"></script>
    <script src="../resources/audit-util.js"></script>
  </head>
  <body>
    <script>
      'use strict';
      // This specific sample rate is chosen to avoid the round/truncation error
      // in delay time. See: crbug.com/448801
      const SAMPLE_RATE = 32768;

      // Web Audio API's rendering quantum.
      const RENDERING_QUANTUM = 128;

      // 4x of rendering quantum. This is to make the rendered result long
      // enough so that we can observe the delayed output.
      const RENDER_LENGTH = RENDERING_QUANTUM * 4;

      // 1x rendering quantum of delay.
      const DELAY_TIME = RENDERING_QUANTUM / SAMPLE_RATE;

      // Use 2 channels as a test case.
      const NUMBER_OF_CHANNELS = 2;

      promise_test(async t => {
        const context = new OfflineAudioContext(
            NUMBER_OF_CHANNELS, RENDER_LENGTH, SAMPLE_RATE);

        const merger = new ChannelMergerNode(context, { numberOfInputs: 2 });
        const delay = new DelayNode(context, {
          maxDelayTime: DELAY_TIME,
          delayTime: DELAY_TIME
        });
        const source = new AudioBufferSourceNode(context);

        // Create a mono source buffer filled with '1'.
        source.buffer = createConstantBuffer(context, RENDER_LENGTH, [1]);

        delay.delayTime.value = DELAY_TIME;

        // Connect the source to input 0 of the merger. Connect the output of
        // the merger to a delay node whose output is then connected to input 1
        // of the merger. See: crbug.com/442925
        source.connect(merger, 0, 0);
        delay.connect(merger, 0, 1);
        merger.connect(delay);
        merger.connect(context.destination);
        source.start();

        const renderedBuffer = await context.startRendering();
        // Expected output values: the output of delay node will be a stereo
        // signal of [1, 0]. When it feeds back to the 2nd input of merger
        // node, the stereo channel will be summed to mono resulting in 0.5.
        const expectedLeft = new Array(RENDER_LENGTH).fill(1.0);
        const expectedRight = [];
        for (let i = 0; i < RENDER_LENGTH; i++) {
          // Note that the delayed channel will be zero for the first 128
          // samples due to the cyclic audio graph, the second 128 sample will
          // be also zero because of 128 samples delay.
          expectedRight[i] = (i < RENDERING_QUANTUM * 2) ? 0.0 : 0.5;
        }

        const actualLeft = renderedBuffer.getChannelData(0);
        const actualRight = renderedBuffer.getChannelData(1);
        assert_array_equals(
            Array.from(actualLeft),
            expectedLeft,
            'Left channel should remain at 1.0 throughout.'
        );
        assert_array_equals(
            Array.from(actualRight),
            expectedRight,
            'Right channel should be silent initially and then 0.5.'
        );

      },'Test that the ChannelMerger with a cyclic graph renders as expected');
    </script>
  </body>
</html>
